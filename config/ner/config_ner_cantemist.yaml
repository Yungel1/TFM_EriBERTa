paths:
  raw:
    train: "datasets/NER/CANTEMIST/train/brat" # Carpeta que contiene los archivos de texto y anotaciones de train
    dev: "datasets/NER/CANTEMIST/dev/brat" # Carpeta que contiene los archivos de texto y anotaciones de dev
    test: "datasets/NER/CANTEMIST/test/brat" # Carpeta que contiene los archivos de texto y anotaciones de test
  json_raw:
    train: "datasets/NER/CANTEMIST/train/train.json" # Datos de train en formato JSON
    dev: "datasets/NER/CANTEMIST/dev/dev.json" # Datos de dev en formato JSON
    test: "datasets/NER/CANTEMIST/test/test.json" # Datos de test en formato JSON
  processed:
    train: "datasets/NER/CANTEMIST/processed/train/train.hf" # HF Dataset con los datos de train
    dev: "datasets/NER/CANTEMIST/processed/dev/dev.hf" # HF Dataset con los datos de dev
    test: "datasets/NER/CANTEMIST/processed/test/test.hf" # HF Dataset con los datos de test
  gemma_processed:
    train: "datasets/NER/CANTEMIST/gemma_processed/train/train.hf" # HF Dataset con los datos de train para gemma 3
    dev: "datasets/NER/CANTEMIST/gemma_processed/dev/dev.hf" # HF Dataset con los datos de dev para gemma 3
    test: "datasets/NER/CANTEMIST/gemma_processed/test/test.hf" # HF Dataset con los datos de test para gemma 3
  label_map: "datasets/NER/CANTEMIST/label_map/label2id.json"

models:
  eriberta:
    results: "results/eriberta/NER/CANTEMIST/"
    model_name: "HiTZ/EriBERTa-base"
    wandb_project: "eriberta-ner-CANTEMIST"
    hyperparameters:
      batch_size: 8
      learning_rate: 5.0e-5
      weight_decay: 0.0

  eriberta_private:
    results: "results/eriberta/private/CANTEMIST/"
    model_name: "eriberta_models/private/eriberta"
    wandb_project: "eriberta-private-CANTEMIST"
    hyperparameters:
      batch_size: 8
      learning_rate: 5.0e-5
      weight_decay: 0.0

  longformer:
    results: "results/eriberta_longformer/public/CANTEMIST/"
    model_name: "eriberta_models/public/EriBERTa_Free_longformer_1024_attn_2048_max_size"
    wandb_project: "eriberta_longformer-public-CANTEMIST"
    hyperparameters: # TODO
      batch_size: 8
      learning_rate: 1.0e-5
      weight_decay: 0.0

  bsc:
    results: "results/bsc/public/CANTEMIST/"
    model_name: "PlanTL-GOB-ES/bsc-bio-ehr-es"
    wandb_project: "bsc-public-CANTEMIST"
    hyperparameters:
      batch_size: 8
      learning_rate: 7.5e-5
      weight_decay: 0.2

  clin_x_es:
    results: "results/clin_x_es/public/CANTEMIST/"
    model_name: "llange/xlm-roberta-large-spanish-clinical"
    wandb_project: "clin_x_es-public-CANTEMIST"
    hyperparameters: # TODO
      batch_size: 8
      learning_rate: 1.0e-5
      weight_decay: 0.0

  mdeberta:
    results: "results/mdeberta/public/CANTEMIST/"
    model_name: "microsoft/mdeberta-v3-base"
    wandb_project: "mdeberta-public-CANTEMIST"
    hyperparameters: # TODO
      batch_size: 8
      learning_rate: 1.0e-5
      weight_decay: 0.0